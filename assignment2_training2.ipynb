{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download the fashion minist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test)= datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the classess in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[\"T-shirt\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot a image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(x, y, labels):\n",
    "    plt.figure(figsize=(15,2))\n",
    "    plt.imshow(x[labels])\n",
    "    plt.xlabel(classes[y[labels]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAADcCAYAAADa3YUtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAarUlEQVR4nO3de3DTZboH8G/S5tJLklLaps1Cl+INWLXIpaUtqyjVrrcDwu5BZ89YVgdXLCjgjIqr3GbH7uCqeKlynO2h486CDHNOYSgsRy20XdgWsEAV6HaRrVIsLQVs0lvaXJ7zRw9xw/uGt+nFpLPPZyYz5Pm9Sd5fyJNf3zfvRUNEBMZYQNpQV4CxcMdJwpgCJwljCpwkjClwkjCmwEnCmAInCWMKnCSMKXCSMKbAScKYwoglSVFRESZMmACj0YjMzEwcOXJkpF6KsRGlGYmxW9u3b8fjjz+OzZs3IzMzE5s2bcKOHTvQ0NCApKSk6z7W6/WiubkZJpMJGo1muKvGGACAiNDR0QGbzQatVnGtoBGQkZFBBQUFvvsej4dsNhsVFhYqH9vU1EQA+Ma3H+TW1NSk/ExGYpj19fWhtrYWq1ev9sW0Wi1yc3NRXV0tlO/t7UVvb6/vPv3/hW02HkAkdMNdPcYAAG64cBB7YTKZlGWHPUkuXboEj8cDq9XqF7darfjb3/4mlC8sLMT69eslFdMhUsNJwkZI/3fxgP6kD3nv1urVq2G32323pqamUFeJMT/DfiVJSEhAREQEWltb/eKtra1ITk4WyhsMBhgMhuGuBmPDZtivJHq9HtOnT0d5ebkv5vV6UV5ejqysrOF+OcZG3LBfSQBg1apVyM/Px4wZM5CRkYFNmzahq6sLv/rVr0bi5RgbUSOSJIsWLUJbWxvWrFmDlpYWTJ06Ffv27RMa84yNBiPyY+JQOBwOWCwWzME87t1iI8ZNLlRgF+x2O8xm83XLhrx3i7Fwx0nCmAInCWMKnCSMKXCSMKbAScKYAicJYwoj8mMiGyaBRqgG8dNWxNh4afy7vJuFmHlrzYCfN1DdNJHib1vk6hv48wYjmEl5Q/g5kK8kjClwkjCmwEnCmAInCWMKnCSMKXDvVhjTRERI4+R2CzHt1CnSsvW/jpXGtT1iTNeVIS0b2eMVy37yubxuwfRkSXqnAp0zNOL3eTCvpYn0/6hriADxbZTiKwljCpwkjClwkjCmwEnCmAI33MPYtY3Nq2QN96a8OGnZX2b9RRo/1DZRiH1jEJd8AgCKEmORufKVb25+/1sh5v76nLSsbKiI7NwCiRgzRn7A4xFDDsc1Lz3w1+ErCWMKnCSMKXCSMKbAScKYAicJYwrcuxXGvE7ngMv23dEpjf/cIh8+YtS6hFilVhx+AgDf7h8vxDy3y1/vmzfF/T68x7OlZceeFHuhzMcvSMteuvNHQqxtunwilVUyd2zMZ2f97pO3D7gkfbiArySMKXCSMKbAScKYAicJYwrccA8XspU/Aqzw0fnvs4TY41MqpGXPuhKl8XH6K0LsF7Zaed3+Q4y/13CXtGjXPyxCTBsjP4+WWeJ39Lfz5PUllziMZMwx+cdXm98qxBx9/sNw3C4nsEv6cPH5BlaMsX9dnCSMKXCSMKbAScKYAicJYwrcuzWSglmrNgizXjwixO6OPR3Uc/wIYo9TF+mlZds9MUJs7ZQ90rJtN4vDUlwk/5j94Yw4XKVT0jsGABFu8b2c9cRxadmF8UeF2Mb/vs3vvpvEYTmB8JWEMQVOEsYUOEkYU+AkYUyBG+4jaQgbx1zPmc4kIXbZLF/OtMUdJ42PjRDng5hka58CmKATJ160ecQGOgBE6MQ5KX0kX7p0/U92CzHnZHETIADQacS5J9nGZmnZX5x+XIjF4B/SsgPBVxLGFDhJGFPgJGFMIegkqaqqwsMPPwybzQaNRoOdO3f6HScirFmzBikpKYiKikJubi7OnDkzXPVl7AcXdJJ0dXUhPT0dRUVF0uMbN27EO++8g82bN+Pw4cOIiYlBXl4enEEsasBYOAm6d+v+++/H/fffLz1GRNi0aRNeeeUVzJs3DwDw0UcfwWq1YufOnXj00UeHVlsGAEg0iD1TRo18mIVeI1/zttklrqN7pucWadm/O8TetJ9ZT0nLuiQ9WRGSITCAvMfKpvtOWtZJYq9XoIElOVaxJ+tEgLIDMaxtksbGRrS0tCA3N9cXs1gsyMzMRHV1tfQxvb29cDgcfjfGwsmwJklLSwsAwGq1+sWtVqvv2LUKCwthsVh8t/HjxTWeGAulkPdurV69Gna73XdramoKdZUY8zOsSZKc3L+/RWur/0T81tZW37FrGQwGmM1mvxtj4WRYh6WkpaUhOTkZ5eXlmDp1KgDA4XDg8OHDWLp06XC+1OgQxO6yss1rAm1Sc1fcl0KszSP/cmn3REvjcRHdQqzDbZSWvdIjPsckg3w50mPdE4RYol7eGJfV4eu+BGnZmwzin+sbW+dKy443iivBuOfe6X/f7QQqBrZcStBJ0tnZia+++sp3v7GxESdOnEB8fDxSU1OxYsUK/Pa3v8VNN92EtLQ0vPrqq7DZbJg/f36wL8VYWAg6ST7//HPcfffdvvurVq0CAOTn56OkpAQvvPACurq68NRTT6G9vR2zZ8/Gvn37YDTKv6UYC3dBJ8mcOXNA1xndqtFosGHDBmzYsGFIFWMsXIS8d4uxcMdJwpgCT7oaSZI/S4PadvrJydKy90SLk5X+6hQ3uQGAxMgOaVw2fCTFYJeWNVnFcXeBes3iI8UhMx0eyR7XAKK1vUIsUH2n6cWJXys/myYta7r1shAz6/yvB94grg98JWFMgZOEMQVOEsYUOEkYU+CG+wjS6MRlQ4PZUTfhyz5p/JJHnFsRpxWHeACAXjJnA5CvYJId3ygt2yZpeB/rSZOWNUWIK64kauWN8fE6sYH9pVM+Cnxv141C7MmHPpOW3fbhvUJMv++vfve1vMwpY8OHk4QxBU4SxhQ4SRhT4CRhTGH0924F2ChHEyn2AGkiAnwnaMW41ykOmeg/IO8tkiGXvHdqoN7+z/ek8SbJ+r4tLjEGyCc2AYAH4vtW0yPfQMeoFXuCEiPlC3Y4vPIhKDIdXnH6hGy4TKA6vDhWvp7b/9hzpfHB4isJYwqcJIwpcJIwpsBJwpjCqGq4y+ZiyOZhAPJGcxAjEYZFz7wMIdY0X97w/+Ud4o66LW75RjnHJSuSWCTDQQAgRjJnA5AvG9rcJ1+dRdZols0bAYAkSYPeQ/Lv4m8lS60GIuuAOO+W16Hj38RhMHEfDfilBHwlYUyBk4QxBU4SxhQ4SRhT4CRhTGFU9W4F6skaqMgU+aLdrjSrELsyWb4aSHeyOJxj6gP10rKLrVuEWKA1e3WSzXaaXGOlZe+I/lqI7bdPkZa9FCnfulrWG5YdIx/m0e4V3wtbpHx93xe/+rkQs0bLJ1394cd7hZiLxC2uAaDBZRBidq98CMuzUw4IsVIkSssOBF9JGFPgJGFMgZOEMQVOEsYURlXDvff+mUIs6TfiTqsAMNV8XohNiTooLev0ikM0ZEMxAOB0j7icaLdXXBUFAM70iR0Fdre8QyBCIzZYL/bJh6W80SjOlyjP2Cwt+0rzz6RxbZS4BOtlj7yRvzBWNndEfM8A4NepVUJsov6itGxZV4oQk+0KDABWnbgE6wRdm7TsAtPfhRg33BkbQZwkjClwkjCmwEnCmAInCWMKYdu7pYmMhEbjX73M144K5eaaTkkf303iMAZZLxYQuEdFxhIpTv7pdcnfxouuge9Jf7NkC+ZHzCekZaveyxRis53LpWXP3iMOjQGA8h5xSEebW17fRxvvEWLHzsnX7J01QVxP+DbTt9Kysp4+U4R8rWTZsJ0ur/h/DAA1Tnkv3WDxlYQxBU4SxhQ4SRhT4CRhTCFsG+4Xlk5HhMF/Gcx1lneFcluvzJI+frzxihD7sWQHVwBIj/pmwPUyacWG5S1m+TyXsq5xQqyifZK0bIquXYj9pfsGadmP170uxBavfF5aNmvv09K4Y4L4/eiOEYeqAIA5Xdxs55U79kjLyjYNCrhTr6FLiAVallVG1jkDACatOFcm4hb/TYDI0wvIp88I+ErCmAInCWMKnCSMKQSVJIWFhZg5cyZMJhOSkpIwf/58NDQ0+JVxOp0oKCjA2LFjERsbi4ULF6K1tXVYK83YDymoJKmsrERBQQFqamrw6aefwuVy4b777kNX1/cNsJUrV2L37t3YsWMHKisr0dzcjAULFgx7xRn7oQTVu7Vv3z6/+yUlJUhKSkJtbS3uvPNO2O12FBcXY+vWrbjnnv6hDFu2bMHkyZNRU1ODWbPkPVEy0Re9iND7T0Qqc0wVyk2Mkk+8ueQSJyz9b+dt0rLjosSVPwKtrXujZPjICWectOy+tp8IMVuUfPObVpe4gc5lV4y0bLdkOEbxW29Ky77RKt/Q5pH4Y0IsXS/2YgFAu1f8Lj0tmVAGyDfmka07DAB2Sa+XbItrAHCR+FGNCLCyimy7bsdt/ivPuF3OH6Z3y27vny0WHx8PAKitrYXL5UJu7vf/MZMmTUJqaiqqq6ulz9Hb2wuHw+F3YyycDDpJvF4vVqxYgZycHNx6660AgJaWFuj1esTFxfmVtVqtaGkRv4GB/naOxWLx3caPlw+cYyxUBp0kBQUFOHnyJD7++OMhVWD16tWw2+2+W1NT05Cej7HhNqhf3JctW4aysjJUVVVh3Ljvf1VOTk5GX18f2tvb/a4mra2tSE6W/w1rMBhgMMh/OWUsHASVJESE5cuXo7S0FBUVFUhLS/M7Pn36dOh0OpSXl2PhwoUAgIaGBpw7dw5ZWVlBVSz2215ERvovKeolcYnR/ZfkwzysRnFpzakm+VWqoVtM4C97bNKyxyJThVhUhHxlFYteHMISEynfVCdBJ9Y3zSBfZUQ29OOoU6wXACxNrJDGz7nFOTS7u26Wlj3dLb4XYyTzagDgS4dYttstX02m1yN+/JxueeeKxSC+lzPj5cOJGiCuwtKW7v9Hk9epBXZKHy4IKkkKCgqwdetW7Nq1CyaTydfOsFgsiIqKgsViwZNPPolVq1YhPj4eZrMZy5cvR1ZWVlA9W4yFk6CS5IMPPgAAzJkzxy++ZcsWLF68GADw1ltvQavVYuHChejt7UVeXh7ef//9YaksY6EQ9J9bKkajEUVFRSgqKhp0pRgLJzx2izEFThLGFMJ20pX24BfQavyHM+z4JEco9+q8HdLHV0omN5W1yHtOHH1iF3RitDghCADMkl6oeJ28rGxlFaNk1Q8A+M4tDkHp1cqHc3gg9vK19IrDWgDgkPcmadwl2QCnN8CmOLLeuyt9CdKytihxzd4OtzhUBQC+7ogXYpfs8pVOnNHiR/WgRz4p7WfJ4go6URf93zNPr/geBsJXEsYUOEkYU+AkYUyBk4QxBQ0N5MePH5DD4YDFYsEczEOkRt5w/Wf2X8p/yZ/4TIMQy4gTl+AEgGMOcUjHOUmjEgBckrkVOq18XkO0rk+IGQMMYdFHiENNtJD/13glDfeYCPG1gMDDYMyR4jCPQEuMaiUbDAUSIanzEfuEAT/eFKC+bhLf9yzLWWnZ/2rMFmKWB7665vlcqMAu2O12mM3XX46WrySMKXCSMKbAScKYAicJYwqcJIwphG/vlnaB2LvlFXuAgtG1UNz8BgAyXxY3B8o0yXtOJunFNcR0kPf+GCW9QjFa+XAIp+S/IdA32MEecR0AT4DS+7+bLI27JL1Frd3yXh6dpOctENnEuB53gNVSesThKhFa+cfRWSEOgxl7Wt5TaNgr/n9ei3u3GBtGnCSMKXCSMKbAScKYQvg23Ac4LOWHppkpzknpSY6SljVcFodYdPxYXtZ8VpyTou2Vzz3x1tVfr4psALjhztgw4iRhTIGThDEFThLGFDhJGFMI29VSwhUd/VKIydcCkTP/deBlBz7ViY0kvpIwpsBJwpgCJwljCpwkjClwkjCmwEnCmAInCWMKnCSMKXCSMKYQdr+4X53e4oYLAVb5ZGzI3OhfRGIg06nCLkk6Ovo3yTmIvSGuCftX0NHRAYtFvgHSVWE3M9Hr9aK5uRkmkwkdHR0YP348mpqalLPHRhuHw8HnFkJEhI6ODthsNmi11291hN2VRKvVYty4cQAAjaZ/DSez2Ry2b/ZQ8bmFjuoKchU33BlT4CRhTCGsk8RgMGDt2rUwGMTdcUc7PrfRI+wa7oyFm7C+kjAWDjhJGFPgJGFMIayTpKioCBMmTIDRaERmZiaOHDkS6ioFraqqCg8//DBsNhs0Gg127tzpd5yIsGbNGqSkpCAqKgq5ubk4c+ZMaCobhMLCQsycORMmkwlJSUmYP38+Ghr8dzx2Op0oKCjA2LFjERsbi4ULF6K1VdzfJdyFbZJs374dq1atwtq1a3Hs2DGkp6cjLy8PFy9eDHXVgtLV1YX09HQUFRVJj2/cuBHvvPMONm/ejMOHDyMmJgZ5eXlwOuXbRYeLyspKFBQUoKamBp9++ilcLhfuu+8+dHV9v6bxypUrsXv3buzYsQOVlZVobm7GggULQljrQaIwlZGRQQUFBb77Ho+HbDYbFRYWhrBWQwOASktLffe9Xi8lJyfT66+/7ou1t7eTwWCgbdu2haCGg3fx4kUCQJWVlUTUfx46nY527NjhK1NfX08AqLq6OlTVHJSwvJL09fWhtrYWubm5vphWq0Vubi6qq6tDWLPh1djYiJaWFr/ztFgsyMzMHHXnabfbAQDx8fEAgNraWrhcLr9zmzRpElJTU0fduYVlkly6dAkejwdWq9UvbrVa0dLSEqJaDb+r5zLaz9Pr9WLFihXIycnBrbfeCqD/3PR6PeLi4vzKjrZzA8JwgCMbfQoKCnDy5EkcPHgw1FUZEWF5JUlISEBERITQE9La2ork5OQQ1Wr4XT2X0Xyey5YtQ1lZGQ4cOOAbvQ30n1tfXx/a29v9yo+mc7sqLJNEr9dj+vTpKC8v98W8Xi/Ky8uRlZUVwpoNr7S0NCQnJ/udp8PhwOHDh8P+PIkIy5YtQ2lpKfbv34+0tDS/49OnT4dOp/M7t4aGBpw7dy7sz00Q6p6DQD7++GMyGAxUUlJCp0+fpqeeeori4uKopaUl1FULSkdHBx0/fpyOHz9OAOjNN9+k48eP0zfffENERL/73e8oLi6Odu3aRV988QXNmzeP0tLSqKenJ8Q1v76lS5eSxWKhiooKunDhgu/W3d3tK/P0009Tamoq7d+/nz7//HPKysqirKysENZ6cMI2SYiI3n33XUpNTSW9Xk8ZGRlUU1MT6ioF7cCBA4T+2fp+t/z8fCLq7wZ+9dVXyWq1ksFgoLlz51JDQ0NoKz0AsnMCQFu2bPGV6enpoWeeeYbGjBlD0dHR9Mgjj9CFCxdCV+lB4lHAjCmEZZuEsXDCScKYAicJYwqcJIwpcJIwpsBJwpgCJwljCpwkjClwkoTYunXrMHXq1IDHS0pKhOHmwVq8eDHmz58/pOf4V8ZJMkTV1dWIiIjAgw8+GOqqhNycOXOwYsWKUFdj2HGSDFFxcTGWL1+OqqoqNDc3h7o6bARwkgxBZ2cntm/fjqVLl+LBBx9ESUmJ3/GKigpoNBqUl5djxowZiI6ORnZ2trCqyD87e/YsJk6ciGXLlgXcYGbXrl2YNm0ajEYjJk6ciPXr18Ptdivru379eiQmJsJsNuPpp59GX1+f71hvby+effZZJCUlwWg0Yvbs2Th69Kjf4ysrK5GRkQGDwYCUlBS89NJLvtddvHgxKisr8fbbb0Oj0UCj0eDrr79W1mlUCPEAy1GtuLiYZsyYQUREu3fvphtuuIG8Xq/v+NURwJmZmVRRUUGnTp2in/70p5Sdne0rs3btWkpPTyciorq6OkpOTqbf/OY3vuNbtmwhi8Xiu19VVUVms5lKSkro7Nmz9Mknn9CECRNo3bp1AeuZn59PsbGxtGjRIjp58iSVlZVRYmIivfzyy74yzz77LNlsNtq7dy+dOnWK8vPzacyYMXT58mUiIjp//jxFR0fTM888Q/X19VRaWkoJCQm0du1aIupf+CErK4uWLFniGzbvdrsH/d6GE06SIcjOzqZNmzYREZHL5aKEhAQ6cOCA7/jVJPnss898sT179hAA33yRq0ly6NAhGjNmDP3+97/3e41rk2Tu3Ln02muv+ZX54x//SCkpKQHrmZ+fT/Hx8dTV1eWLffDBBxQbG0sej4c6OztJp9PRn/70J9/xvr4+stlstHHjRiIievnll+mWW27x+xIoKiryPQcR0V133UXPPffc9d6yUYn/3BqkhoYGHDlyBI899hgAIDIyEosWLUJxcbFQ9vbbb/f9OyUlBQD81g87d+4c7r33XqxZswbPP//8dV+3rq4OGzZsQGxsrO+2ZMkSXLhwAd3d3QEfl56ejujoaN/9rKwsdHZ2oqmpCWfPnoXL5UJOTo7vuE6nQ0ZGBurr6wEA9fX1yMrK8m2sBAA5OTno7OzE+fPnr1vn0Y4Xghik4uJiuN1u2Gw2X4yIYDAY8N577/ntoqTT6Xz/vvoh83q9vlhiYiJsNhu2bduGJ5544rq7Q3V2dmL9+vXSRd6MRuOQzonJ8ZVkENxuNz766CO88cYbOHHihO9WV1fn+7AHIyoqCmVlZTAajcjLy/Ntriozbdo0NDQ04MYbbxRu19v7r66uDj09Pb77NTU1iI2Nxfjx43HDDTdAr9fj0KFDvuMulwtHjx7FlClTAACTJ09GdXW1X2fCoUOHYDKZfAtA6PV6eDyeoM59VAj133ujUWlpKen1empvbxeOvfDCC77G/NU2yXfffec7fnWue2NjIxH5N9w7Ojpo9uzZlJOTQx0dHUQktkn27dtHkZGRtG7dOjp58iSdPn2atm3b5tfYv9bVhvtjjz1Gp06doj179pDVaqWXXnrJV+a5554jm81Gf/7zn/0a7leuXCGi7xvuBQUFVF9fTzt37vRruBMRLVmyhGbOnEmNjY3U1tbma6uMdpwkg/DQQw/RAw88ID12+PBhAkB1dXVBJwlRf6JkZ2fTnXfeSZ2dnUKSEPUnSnZ2NkVFRZHZbKaMjAz68MMPA9Y3Pz+f5s2bR2vWrKGxY8dSbGwsLVmyhJxOp69MT08PLV++nBISEshgMFBOTg4dOXLE73kqKipo5syZpNfrKTk5mV588UVyuVy+4w0NDTRr1iyKioryO8fRjue4M6bAbRLGFDhJGFPgJGFMgZOEMQVOEsYUOEkYU+AkYUyBk4QxBU4SxhQ4SRhT4CRhTIGThDGF/wOAAyjjSIGqBgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(x_train, y_train, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mormalie the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make an ann model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\miniconda3\\envs\\assignment1\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "ann= models.Sequential([\n",
    "        layers.Flatten(input_shape=(28,28)),\n",
    "        layers.Dense(300,activation='relu'),\n",
    "        layers.Dense(200,activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(30,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile the model by setting up (optimier, loss function, metrices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model on the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6376 - loss: 1.1599\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.5315\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.4585\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.4300\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8556 - loss: 0.4073\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.3947\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 0.3719\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8689 - loss: 0.3666\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.3564\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.3413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14a10e051e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x_train,y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8717 - loss: 0.3658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3696742057800293, 0.8682000041007996]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see the result of the predicted image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred= ann.predict(x_test)\n",
    "np.argmax(y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make model2 using conveloution neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn= models.Sequential([\n",
    "    layers.Conv2D(filters=32,kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(filters=32,kernel_size=(3,3), activation='relu' ),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile the model by setting up (optimier, loss function, metrices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model on the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.5482 - loss: 1.2659\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.7962 - loss: 0.5489\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 0.4666\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8434 - loss: 0.4285\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 0.4003\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8649 - loss: 0.3757\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8701 - loss: 0.3555\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8713 - loss: 0.3524\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8764 - loss: 0.3438\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8802 - loss: 0.3266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14a11b67a30>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x_train,y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8797 - loss: 0.3464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3467258810997009, 0.8761000037193298]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see the result of the predicted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred= cnn.predict(x_test)\n",
    "np.argmax(y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see from the results of training the models on the same data the accuracy of the cnn model is better and in the evaluating step the cnn is better with 0.008% accuracy so we can conclude that in image processing ussing a cnn will be better and more efficient**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
